#!/usr/bin/env python3
"""
Diagram Figure Reasoner - æ ¹æ®è®ºæ–‡å†…å®¹å’Œå›¾ç‰‡åˆ†æç”Ÿæˆç»˜å›¾æŒ‡ä»¤

åŠŸèƒ½ï¼š
1. è¯»å–markdownæ–‡æ¡£
2. æå–diagramå›¾ç‰‡çš„captionå’Œä¸Šä¸‹æ–‡
3. ä½¿ç”¨GPT-4oåˆ†æå›¾ç‰‡å†…å®¹
4. ç”Ÿæˆç»˜å›¾æŒ‡ä»¤
5. ä½¿ç”¨GPT-o3æ€»ç»“æˆç‰¹å®šæ ¼å¼
"""

import os
import re
import json
import requests
import base64
from pathlib import Path
from typing import Dict, List

# FAISS dense retrieval imports
try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_openai import OpenAIEmbeddings, AzureOpenAIEmbeddings
    from langchain.schema import Document
    HAS_LANGCHAIN = True
except ImportError:
    HAS_LANGCHAIN = False
    print("âš ï¸ langchain æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨FAISSæ£€ç´¢")

# å°è¯•å¯¼å…¥ dotenvï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç®€å•çš„ç¯å¢ƒå˜é‡åŠ è½½
try:
    from dotenv import load_dotenv
    HAS_DOTENV = True
except ImportError:
    HAS_DOTENV = False
    print("âš ï¸ python-dotenv æœªå®‰è£…ï¼Œä½¿ç”¨ç®€å•ç¯å¢ƒå˜é‡åŠ è½½")

def load_env_vars():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    # å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½ .env æ–‡ä»¶
    env_paths = [
        Path(__file__).parent / ".env",
        Path(__file__).parent.parent / ".env",
        Path(__file__).parent.parent.parent / "CoTT" / ".env",
        Path(__file__).parent.parent.parent / "CoTT" / ".env_old",
        Path("/Users/suny0a/Proj/MM-Reasoning/CoTT/.env"),  # ç»å¯¹è·¯å¾„
    ]
    
    if HAS_DOTENV:
        for env_path in env_paths:
            if env_path.exists():
                print(f"ğŸ“„ åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
                load_dotenv(env_path)
                return True
    else:
        # ç®€å•çš„ç¯å¢ƒå˜é‡åŠ è½½
        for env_path in env_paths:
            if env_path.exists():
                print(f"ğŸ“„ ä»æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
                with open(env_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            os.environ[key] = value
                
                # è®¾ç½®é»˜è®¤çš„ Azure OpenAI é…ç½®
                if not os.getenv("AZURE_OPENAI_ENDPOINT"):
                    os.environ["AZURE_OPENAI_ENDPOINT"] = "https://linjl-ma65uv6u-eastus2.cognitiveservices.azure.com/"
                if not os.getenv("AZURE_OPENAI_DEPLOYMENT"):
                    os.environ["AZURE_OPENAI_DEPLOYMENT"] = "gpt-4o"
                if not os.getenv("AZURE_OPENAI_API_VERSION"):
                    os.environ["AZURE_OPENAI_API_VERSION"] = "2024-02-15-preview"
                print(f"   âœ… è®¾ç½®é»˜è®¤ Azure OpenAI é…ç½®")
                return True
    
    print("âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶")
    return False

# åŠ è½½ç¯å¢ƒå˜é‡
load_env_vars()

def extract_diagram_figures(markdown_content: str) -> List[Dict]:
    """ä»markdownå†…å®¹ä¸­æå–diagramå›¾ç‰‡ä¿¡æ¯ï¼ˆæ’é™¤é™„å½•ä¸­çš„å›¾ç‰‡ï¼‰"""
    figures = []
    
    # æ‰¾åˆ°é™„å½•å¼€å§‹çš„ä½ç½®ï¼ˆæ’é™¤é™„å½•å†…å®¹ï¼‰
    lines = markdown_content.split('\n')
    appendix_start_idx = len(lines)  # é»˜è®¤æ²¡æœ‰é™„å½•
    for i, line in enumerate(lines):
        line_lower = line.lower().strip()
        # æ£€æŸ¥æ˜¯å¦æ˜¯é™„å½•æ ‡é¢˜
        if (line_lower.startswith('# appendix') or 
            line_lower.startswith('## appendix') or
            line_lower.startswith('### appendix') or
            line_lower.startswith('# supplementary') or
            line_lower.startswith('## supplementary') or
            line_lower.startswith('### supplementary') or
            'appendix' in line_lower and line_lower.startswith('#')):
            appendix_start_idx = i
            break
    
    # åªå¤„ç†æ­£æ–‡éƒ¨åˆ†ï¼ˆæ’é™¤é™„å½•ï¼‰
    main_content = '\n'.join(lines[:appendix_start_idx])
    
    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡å¼•ç”¨
    figure_pattern = r'<figure[^>]*id="([^"]*)"[^>]*>.*?<embed[^>]*src="([^"]*)"[^>]*/>.*?<figcaption>(.*?)</figcaption>.*?</figure>'
    matches = re.findall(figure_pattern, main_content, re.DOTALL)
    
    for match in matches:
        fig_id, src, caption = match
        # æ¸…ç†captionä¸­çš„HTMLæ ‡ç­¾å’Œå¤šä½™ç©ºç™½
        caption = re.sub(r'<[^>]+>', '', caption).strip()
        caption = re.sub(r'\s+', ' ', caption)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯diagramç›¸å…³çš„å›¾ç‰‡ï¼Œå¹¶æ’é™¤é™„å½•ä¸­çš„å›¾ç‰‡
        if (('diagram' in fig_id.lower() or 'diagram' in caption.lower() or
             'architecture' in fig_id.lower() or 'architecture' in caption.lower() or
             'framework' in fig_id.lower() or 'framework' in caption.lower() or
             'pipeline' in fig_id.lower() or 'pipeline' in caption.lower() or
             'overview' in fig_id.lower() or 'overview' in caption.lower() or
             'structure' in fig_id.lower() or 'structure' in caption.lower()) and 
            'appendix_figures' not in src):
            figures.append({
                'id': fig_id,
                'src': src,
                'caption': caption,
                'type': 'diagram'
            })
    
    return figures


class FAISSRetriever:
    """åŸºäºFAISSçš„å¯†é›†å‘é‡æ£€ç´¢å™¨"""
    
    def __init__(self):
        self.vector_store = None
        self.documents = []
        self.embeddings = None
        
    def _get_embeddings(self):
        """è·å–embeddingæ¨¡å‹"""
        if self.embeddings is not None:
            return self.embeddings
            
        # æ£€æŸ¥Azure OpenAIé…ç½®
        if os.getenv("AZURE_OPENAI_ENDPOINT") and os.getenv("AZURE_OPENAI_API_KEY"):
            endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-06-01")
            
            self.embeddings = AzureOpenAIEmbeddings(
                azure_endpoint=endpoint,
                openai_api_version=api_version,
                openai_api_key=api_key,
                model="text-embedding-3-large"
            )
            print("   ğŸ”— ä½¿ç”¨ Azure OpenAI Embeddings")
        else:
            # ä½¿ç”¨OpenAI API
            self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
            print("   ğŸ”— ä½¿ç”¨ OpenAI Embeddings")
        
        return self.embeddings
    
    def fit(self, documents: List[str]):
        """æ„å»ºFAISSç´¢å¼•"""
        if not HAS_LANGCHAIN:
            raise ImportError("éœ€è¦å®‰è£…langchainæ¥ä½¿ç”¨FAISSæ£€ç´¢")
        
        self.documents = documents
        
        # åˆ›å»ºDocumentå¯¹è±¡
        docs = [Document(page_content=doc) for doc in documents]
        
        # æ–‡æœ¬åˆ†å‰²å™¨
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_documents(docs)
        
        # è·å–embeddingså¹¶æ„å»ºFAISSç´¢å¼•
        embeddings = self._get_embeddings()
        self.vector_store = FAISS.from_documents(chunks, embeddings)
        
        print(f"   ğŸ“Š FAISSç´¢å¼•æ„å»ºå®Œæˆ: {len(chunks)} ä¸ªchunks")
    
    def search(self, query: str, top_k: int = 3) -> List[tuple]:
        """æœç´¢æœ€ç›¸å…³çš„æ–‡æ¡£"""
        if self.vector_store is None:
            return []
        
        # ä½¿ç”¨FAISSæ£€ç´¢
        retriever = self.vector_store.as_retriever(search_kwargs={"k": top_k})
        try:
            # ä½¿ç”¨æ–°çš„invokeæ–¹æ³•
            docs = retriever.invoke(query)
        except AttributeError:
            # å›é€€åˆ°æ—§æ–¹æ³•
            docs = retriever.get_relevant_documents(query)
        
        # è¿”å›ç»“æœ
        results = []
        for i, doc in enumerate(docs):
            # æ‰¾åˆ°åŸå§‹æ–‡æ¡£çš„ç´¢å¼•
            original_idx = self._find_original_doc_index(doc.page_content)
            if original_idx != -1:
                results.append((original_idx, 1.0 - i * 0.1))  # ç®€å•çš„åˆ†æ•°è®¡ç®—
        
        return results
    
    def _find_original_doc_index(self, content: str) -> int:
        """æ‰¾åˆ°chunkå¯¹åº”çš„åŸå§‹æ–‡æ¡£ç´¢å¼•"""
        for i, doc in enumerate(self.documents):
            if content[:100] in doc:  # ä½¿ç”¨å‰100ä¸ªå­—ç¬¦åŒ¹é…
                return i
        return -1


def get_semantic_context_for_figure(markdown_content: str, caption: str) -> str:
    """ä½¿ç”¨FAISSæ£€ç´¢æ‰¾åˆ°ä¸å›¾ç‰‡ç›¸å…³çš„ä¸Šä¸‹æ–‡å†…å®¹"""
    if not HAS_LANGCHAIN:
        print("   âŒ langchain æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨FAISSæ£€ç´¢")
        return ""
    
    lines = markdown_content.split('\n')
    
    # æ‰¾åˆ°é™„å½•å¼€å§‹çš„ä½ç½®ï¼ˆæ’é™¤é™„å½•å†…å®¹ï¼‰
    appendix_start_idx = len(lines)  # é»˜è®¤æ²¡æœ‰é™„å½•
    for i, line in enumerate(lines):
        line_lower = line.lower().strip()
        # æ£€æŸ¥æ˜¯å¦æ˜¯é™„å½•æ ‡é¢˜
        if (line_lower.startswith('# appendix') or 
            line_lower.startswith('## appendix') or
            line_lower.startswith('### appendix') or
            line_lower.startswith('# supplementary') or
            line_lower.startswith('## supplementary') or
            line_lower.startswith('### supplementary') or
            'appendix' in line_lower and line_lower.startswith('#')):
            appendix_start_idx = i
            break
    
    # å°†æ–‡æ¡£åˆ†å‰²æˆæ®µè½ï¼ˆåªè€ƒè™‘æ­£æ–‡éƒ¨åˆ†ï¼Œæ’é™¤é™„å½•ï¼‰
    paragraphs = []
    current_paragraph = []
    
    for i, line in enumerate(lines[:appendix_start_idx]):  # åªå¤„ç†æ­£æ–‡éƒ¨åˆ†
        line = line.strip()
        if not line:
            if current_paragraph:
                paragraphs.append(' '.join(current_paragraph))
                current_paragraph = []
        elif not line.startswith('<figure') and not line.startswith('<embed') and not line.startswith('<figcaption'):
            current_paragraph.append(line)
    
    # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
    if current_paragraph:
        paragraphs.append(' '.join(current_paragraph))
    
    # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ®µè½
    paragraphs = [text for text in paragraphs if len(text) > 50]
    
    if not paragraphs:
        return ""
    
    # ä½¿ç”¨FAISSæ£€ç´¢
    try:
        print("   ğŸ” ä½¿ç”¨FAISSå¯†é›†æ£€ç´¢...")
        retriever = FAISSRetriever()
        retriever.fit(paragraphs)
        
        # æ„å»ºæŸ¥è¯¢ï¼šä½¿ç”¨captionä½œä¸ºæŸ¥è¯¢ï¼Œæ‰©å±•ç›¸å…³è¯æ±‡
        query = caption
        if any(keyword in caption.lower() for keyword in ['diagram', 'architecture', 'framework', 'pipeline', 'overview', 'structure']):
            query += " system design components modules workflow process"
        print(f"   ğŸ” FAISSæŸ¥è¯¢: {query[:100]}...")
        
        # æœç´¢æœ€ç›¸å…³çš„æ®µè½
        results = retriever.search(query, top_k=5)
        
        # æå–ç›¸å…³æ®µè½
        relevant_contexts = []
        for doc_idx, score in results:
            if score > 0:  # åªä¿ç•™æœ‰åˆ†æ•°çš„ç»“æœ
                text = paragraphs[doc_idx]
                relevant_contexts.append(text)
                print(f"   ğŸ“„ æ‰¾åˆ°ç›¸å…³æ®µè½ (åˆ†æ•°: {score:.3f}): {text[:100]}...")
        
        return '\n\n'.join(relevant_contexts)
        
    except Exception as e:
        print(f"   âŒ FAISSæ£€ç´¢å¤±è´¥: {e}")
        return ""


def encode_image(image_path: str) -> str:
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        print(f"   âŒ å›¾ç‰‡ç¼–ç å¤±è´¥: {e}")
        return ""


def analyze_diagram_with_gpt4o(image_path: str, caption: str, context: str) -> Dict:
    """ä½¿ç”¨GPT-4oåˆ†ædiagramå›¾ç‰‡å†…å®¹"""
    
    # Azure OpenAI é…ç½®
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "https://linjl-ma65uv6u-eastus2.cognitiveservices.azure.com/")
    api_key = os.getenv("AZURE_OPENAI_API_KEY", "")
    deployment = "gpt-4o"  # ç›´æ¥ä½¿ç”¨gpt-4oéƒ¨ç½²
    api_version = "2024-02-15-preview"
    
    if not api_key:
        return {"error": "Azure OpenAI API key not found"}
    
    # æ„å»ºè¯·æ±‚URL
    url = f"{endpoint}openai/deployments/{deployment}/chat/completions?api-version={api_version}"
    headers = {"Content-Type": "application/json", "api-key": api_key}
    
    # ç¼–ç å›¾ç‰‡
    base64_image = encode_image(image_path)
    if not base64_image:
        return {"error": "Failed to encode image"}
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""You are analyzing a diagram from a research paper. Based on the image, caption, and context, provide detailed instructions for recreating this diagram.

**Figure Caption:**
{caption}

**Context around the figure:**
{context}

**Your task:**
Analyze the diagram and provide step-by-step instructions for drawing/recreating it. Focus on:
1. Overall structure and layout
2. Key components and their relationships
3. Visual elements (boxes, arrows, labels, etc.)
4. Color schemes and styling
5. Specific positioning and sizing

Please provide your analysis in the following JSON format:
{{
  "diagram_analysis": {{
    "diagram_type": "Type of diagram (e.g., architecture, flowchart, pipeline, etc.)",
    "main_components": ["List of main components/modules"],
    "relationships": ["List of key relationships between components"],
    "visual_elements": ["List of visual elements like boxes, arrows, labels"],
    "layout_structure": "Description of overall layout and organization"
  }},
  "drawing_instructions": {{
    "overall_approach": "General strategy for drawing this diagram",
    "step_by_step": [
      "Step 1: description",
      "Step 2: description",
      "..."
    ],
    "visual_specifications": {{
      "colors": ["List of colors used"],
      "shapes": ["List of shapes used"],
      "arrows": ["List of arrow types and directions"],
      "labels": ["List of labels and text elements"]
    }},
    "layout_guidelines": "Specific instructions for positioning and sizing",
    "styling_notes": "Additional styling and formatting notes"
  }},
  "detailed_description": "Detailed description of what the diagram shows and how it should be drawn"
}}"""

    payload = {
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        "max_tokens": 3000,
        "temperature": 0.1
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        
        data = response.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "{}")
        
        # å°è¯•è§£æJSON
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            result = json.loads(content)
            return result
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æå–markdownä»£ç å—ä¸­çš„JSON
            try:
                # æŸ¥æ‰¾```jsonå’Œ```ä¹‹é—´çš„å†…å®¹
                json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
                if json_match:
                    json_content = json_match.group(1)
                    result = json.loads(json_content)
                    return result
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œè¿”å›åŸå§‹å†…å®¹
                    return {
                        "raw_response": content,
                        "error": "Failed to parse JSON response"
                    }
            except json.JSONDecodeError:
                # å¦‚æœè¿˜æ˜¯è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
                return {
                    "raw_response": content,
                    "error": "Failed to parse JSON response"
                }
            
    except Exception as e:
        return {"error": f"API request failed: {str(e)}"}


def generate_drawing_summary_with_o3(caption: str, context: str, diagram_analysis: Dict, paper_content: str) -> Dict:
    """ä½¿ç”¨GPT-o3ç”Ÿæˆé€‚åˆAIç»˜å›¾å·¥å…·çš„ç®€æ´æŒ‡ä»¤"""
    
    # Azure OpenAI é…ç½®
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "https://linjl-ma65uv6u-eastus2.cognitiveservices.azure.com/")
    api_key = os.getenv("AZURE_OPENAI_API_KEY", "")
    deployment = "o3-DR"  # ç›´æ¥ä½¿ç”¨o3-DRéƒ¨ç½²
    api_version = "2025-01-01-preview"
    
    if not api_key:
        return {"error": "Azure OpenAI API key not found"}
    
    # æ„å»ºè¯·æ±‚URL
    url = f"{endpoint}openai/deployments/{deployment}/chat/completions?api-version={api_version}"
    headers = {"Content-Type": "application/json", "api-key": api_key}
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""You are analyzing a research paper diagram and need to generate a concise drawing instruction for AI image generation tools like DALL-E 3 or Nano Banana.

**Figure Caption:**
{caption}

**Context around the figure:**
{context}

**Diagram Analysis:**
{json.dumps(diagram_analysis, indent=2)}

**Your task:**
Generate a summary in the specific format requested. The output should be in this exact format:

<think>
This paper presents [brief description of the paper's main contribution]. The diagram shows [description of what the diagram illustrates]. The key components include [list main components]. The relationships between components are [describe relationships]. This diagram is important because [explain significance].
</think>

<tool>draw</tool>
<params>
[Generate a concise, clear instruction for AI image generation tools. The instruction should be:
1. Simple and direct (under 200 words)
2. Focus on visual elements that AI can understand and generate
3. Use clear, descriptive language
4. Include key components, layout, and visual style
5. Avoid complex technical jargon
6. Be specific about colors, shapes, and arrangement
7. Suitable for DALL-E 3, Midjourney, or similar AI art tools

Example format: "Create a clean, professional diagram showing [main concept]. The layout should be [layout description]. Include [key components] arranged [how they're arranged]. Use [color scheme] with [visual style]. The diagram should have [specific visual elements] and show [relationships between elements]."]
</params>

Please provide your response in the exact format above."""

    payload = {
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "max_completion_tokens": 4000
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        
        data = response.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        return {
            "summary": content,
            "success": True
        }
            
    except Exception as e:
        return {"error": f"API request failed: {str(e)}"}


def test_diagram_paper(paper_dir: Path, paper_name: str):
    """æµ‹è¯•å•ä¸ªè®ºæ–‡çš„diagramåˆ†æ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“š æµ‹è¯•è®ºæ–‡: {paper_name}")
    print(f"{'='*60}")
    
    # æŸ¥æ‰¾markdownæ–‡ä»¶
    markdown_path = paper_dir / "output_pandoc.md"
    if not markdown_path.exists():
        print(f"âŒ æœªæ‰¾åˆ°markdownæ–‡ä»¶: {markdown_path}")
        return None
    
    print(f"ğŸ“„ è¯»å–markdownæ–‡ä»¶: {markdown_path}")
    try:
        with open(markdown_path, 'r', encoding='utf-8') as f:
            markdown_content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None
    
    # æå–diagramå›¾ç‰‡
    print("\nğŸ” æå–diagramå›¾ç‰‡...")
    figures = extract_diagram_figures(markdown_content)
    
    if not figures:
        print("âŒ æœªæ‰¾åˆ°diagramå›¾ç‰‡")
        return {
            "paper_name": paper_name,
            "paper_dir": str(paper_dir),
            "figures_found": 0,
            "figures": [],
            "results": []
        }
    
    print(f"âœ… æ‰¾åˆ° {len(figures)} ä¸ªdiagramå›¾ç‰‡")
    
    # åˆ†ææ¯ä¸ªå›¾ç‰‡
    results = []
    for i, figure in enumerate(figures, 1):
        print(f"\nğŸ“Š åˆ†æå›¾ç‰‡ {i}: {figure['id']}")
        print(f"   Caption: {figure['caption'][:100]}...")
        
        # æ„å»ºå›¾ç‰‡è·¯å¾„ï¼Œå°†PDFåç¼€æ›¿æ¢ä¸ºPNG
        src_path = figure['src']
        if src_path.endswith('.pdf'):
            src_path = src_path.replace('.pdf', '.png')
        
        image_path = paper_dir / src_path
        if not image_path.exists():
            print(f"   âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            continue
        
        # ä½¿ç”¨æ£€ç´¢æå–ç›¸å…³ä¸Šä¸‹æ–‡
        full_context = get_semantic_context_for_figure(markdown_content, figure['caption'])
        
        # è¾“å‡ºæå–åˆ°çš„ä¸Šä¸‹æ–‡ç”¨äºè°ƒè¯•
        print(f"   ğŸ“„ æå–åˆ°çš„ä¸Šä¸‹æ–‡:")
        print(f"   {'='*50}")
        print(f"   {full_context[:300]}...")
        print(f"   {'='*50}")
        
        # ä½¿ç”¨GPT-4oåˆ†æå›¾ç‰‡
        print("   ğŸ” ä½¿ç”¨GPT-4oåˆ†æå›¾ç‰‡...")
        diagram_analysis = analyze_diagram_with_gpt4o(str(image_path), figure['caption'], full_context)
        
        if "error" in diagram_analysis:
            print(f"   âŒ å›¾ç‰‡åˆ†æå¤±è´¥: {diagram_analysis['error']}")
            continue
        
        print("   âœ… å›¾ç‰‡åˆ†æå®Œæˆ")
        
        # ä½¿ç”¨GPT-o3ç”Ÿæˆæ€»ç»“
        print("   ğŸ” ä½¿ç”¨GPT-o3ç”Ÿæˆç»˜å›¾æŒ‡ä»¤...")
        summary_result = generate_drawing_summary_with_o3(
            figure['caption'], 
            full_context, 
            diagram_analysis,
            markdown_content
        )
        
        if "error" in summary_result:
            print(f"   âŒ æ€»ç»“ç”Ÿæˆå¤±è´¥: {summary_result['error']}")
            # å³ä½¿GPT-o3å¤±è´¥ï¼Œä¹Ÿä¿å­˜GPT-4oçš„åˆ†æç»“æœ
            summary_result = {"error": "GPT-o3 summary generation failed", "diagram_analysis_available": True}
        
        print("   âœ… ç»˜å›¾æŒ‡ä»¤ç”Ÿæˆå®Œæˆ")
        
        result = {
            "figure_info": figure,
            "context": full_context,
            "diagram_analysis": diagram_analysis,
            "drawing_summary": summary_result
        }
        results.append(result)
        
        # æ˜¾ç¤ºç»“æœ
        if "error" not in summary_result or summary_result.get("diagram_analysis_available"):
            print("   ğŸ“‹ ç”Ÿæˆçš„ç»˜å›¾æŒ‡ä»¤:")
            print("   " + "="*50)
            if "summary" in summary_result:
                print(f"   {summary_result.get('summary', '')[:200]}...")
            else:
                print("   GPT-4oåˆ†æç»“æœå·²ä¿å­˜ï¼Œä½†GPT-o3æ€»ç»“ç”Ÿæˆå¤±è´¥")
            print("   " + "="*50)
    
    return {
        "paper_name": paper_name,
        "paper_dir": str(paper_dir),
        "figures_found": len(figures),
        "figures": figures,
        "results": results
    }


def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æ‰€æœ‰è®ºæ–‡çš„diagramåˆ†æ"""
    print("ğŸ” æµ‹è¯•æ‰€æœ‰è®ºæ–‡çš„diagramåˆ†æ")
    print("=" * 60)
    
    # è®ºæ–‡ç›®å½•
    papers_dir = Path(__file__).parent.parent.parent / "workspace" / "papers_latex"
    
    # è·å–æ‰€æœ‰è®ºæ–‡ç›®å½•
    paper_dirs = [d for d in papers_dir.iterdir() if d.is_dir() and d.name.startswith('arXiv-')]
    
    if not paper_dirs:
        print("âŒ æœªæ‰¾åˆ°è®ºæ–‡ç›®å½•")
        return
    
    print(f"ğŸ“š æ‰¾åˆ° {len(paper_dirs)} ä¸ªè®ºæ–‡ç›®å½•")
    
    # æµ‹è¯•æ¯ä¸ªè®ºæ–‡
    all_results = []
    for paper_dir in paper_dirs:
        paper_name = paper_dir.name
        result = test_diagram_paper(paper_dir, paper_name)
        if result:
            all_results.append(result)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœ
    output_path = Path(__file__).parent / "all_diagrams_test_results.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
    print(f"{'='*60}")
    
    total_papers = len(all_results)
    total_figures = sum(r["figures_found"] for r in all_results)
    successful_analyses = 0
    
    for result in all_results:
        paper_name = result["paper_name"]
        figures_found = result["figures_found"]
        successful = sum(1 for r in result["results"] if "error" not in r.get("drawing_summary", {}))
        
        print(f"ğŸ“š {paper_name}:")
        print(f"   ğŸ“Š æ‰¾åˆ° {figures_found} ä¸ªdiagramå›¾ç‰‡")
        print(f"   âœ… æˆåŠŸåˆ†æ {successful}/{figures_found} ä¸ªå›¾ç‰‡")
        
        successful_analyses += successful
    
    print(f"\nğŸ¯ æ€»ä½“ç»Ÿè®¡:")
    print(f"   ğŸ“š æµ‹è¯•è®ºæ–‡æ•°: {total_papers}")
    print(f"   ğŸ“Š æ€»å›¾ç‰‡æ•°: {total_figures}")
    print(f"   âœ… æˆåŠŸåˆ†æ: {successful_analyses}/{total_figures}")
    print(f"   ğŸ“ˆ æˆåŠŸç‡: {successful_analyses/total_figures*100:.1f}%" if total_figures > 0 else "   ğŸ“ˆ æˆåŠŸç‡: N/A")
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


if __name__ == "__main__":
    main()
