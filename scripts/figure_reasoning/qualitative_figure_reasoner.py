#!/usr/bin/env python3
"""
Qualitative Figure Reasoner - æ ¹æ®è®ºæ–‡å†…å®¹å’Œcaptionæ¨ç†å›¾ç‰‡å†…å®¹

åŠŸèƒ½ï¼š
1. è¯»å–markdownæ–‡æ¡£
2. æå–qualitativeå›¾ç‰‡çš„captionå’Œä¸Šä¸‹æ–‡
3. ä½¿ç”¨GPT-o3æ ¹æ®æ–‡æ¡£å†…å®¹æ¨ç†å›¾ç‰‡åº”è¯¥æ˜¾ç¤ºä»€ä¹ˆ
4. ç”Ÿæˆè¯¦ç»†çš„å›¾ç‰‡å†…å®¹æè¿°
"""

import os
import re
import json
import requests
from pathlib import Path
from typing import Dict, List

# FAISS dense retrieval imports
try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_openai import OpenAIEmbeddings, AzureOpenAIEmbeddings
    from langchain.schema import Document
    HAS_LANGCHAIN = True
except ImportError:
    HAS_LANGCHAIN = False
    print("âš ï¸ langchain æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨FAISSæ£€ç´¢")

# å°è¯•å¯¼å…¥ dotenvï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç®€å•çš„ç¯å¢ƒå˜é‡åŠ è½½
try:
    from dotenv import load_dotenv
    HAS_DOTENV = True
except ImportError:
    HAS_DOTENV = False
    print("âš ï¸ python-dotenv æœªå®‰è£…ï¼Œä½¿ç”¨ç®€å•ç¯å¢ƒå˜é‡åŠ è½½")

def load_env_vars():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    # å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½ .env æ–‡ä»¶
    env_paths = [
        Path(__file__).parent / ".env",
        Path(__file__).parent.parent / ".env",
        Path(__file__).parent.parent.parent / "CoTT" / ".env",
        Path(__file__).parent.parent.parent / "CoTT" / ".env_old",
        Path("/Users/suny0a/Proj/MM-Reasoning/CoTT/.env"),  # ç»å¯¹è·¯å¾„
    ]
    
    if HAS_DOTENV:
        for env_path in env_paths:
            if env_path.exists():
                print(f"ğŸ“„ åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
                load_dotenv(env_path)
                return True
    else:
        # ç®€å•çš„ç¯å¢ƒå˜é‡åŠ è½½
        for env_path in env_paths:
            if env_path.exists():
                print(f"ğŸ“„ ä»æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
                with open(env_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            os.environ[key] = value
                
                # è®¾ç½®é»˜è®¤çš„ Azure OpenAI é…ç½®
                if not os.getenv("AZURE_OPENAI_ENDPOINT"):
                    os.environ["AZURE_OPENAI_ENDPOINT"] = "https://linjl-ma65uv6u-eastus2.cognitiveservices.azure.com/"
                if not os.getenv("AZURE_OPENAI_DEPLOYMENT"):
                    os.environ["AZURE_OPENAI_DEPLOYMENT"] = "o3-DR"
                if not os.getenv("AZURE_OPENAI_API_VERSION"):
                    os.environ["AZURE_OPENAI_API_VERSION"] = "2025-01-01-preview"
                print(f"   âœ… è®¾ç½®é»˜è®¤ Azure OpenAI é…ç½®")
                return True
    
    print("âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶")
    return False

# åŠ è½½ç¯å¢ƒå˜é‡
load_env_vars()

def extract_qualitative_figures(markdown_content: str) -> List[Dict]:
    """ä»markdownå†…å®¹ä¸­æå–qualitativeå›¾ç‰‡ä¿¡æ¯ï¼ˆæ’é™¤é™„å½•ä¸­çš„å›¾ç‰‡ï¼‰"""
    figures = []
    
    # æ‰¾åˆ°é™„å½•å¼€å§‹çš„ä½ç½®ï¼ˆæ’é™¤é™„å½•å†…å®¹ï¼‰
    lines = markdown_content.split('\n')
    appendix_start_idx = len(lines)  # é»˜è®¤æ²¡æœ‰é™„å½•
    for i, line in enumerate(lines):
        line_lower = line.lower().strip()
        # æ£€æŸ¥æ˜¯å¦æ˜¯é™„å½•æ ‡é¢˜
        if (line_lower.startswith('# appendix') or 
            line_lower.startswith('## appendix') or
            line_lower.startswith('### appendix') or
            line_lower.startswith('# supplementary') or
            line_lower.startswith('## supplementary') or
            line_lower.startswith('### supplementary') or
            'appendix' in line_lower and line_lower.startswith('#')):
            appendix_start_idx = i
            break
    
    # åªå¤„ç†æ­£æ–‡éƒ¨åˆ†ï¼ˆæ’é™¤é™„å½•ï¼‰
    main_content = '\n'.join(lines[:appendix_start_idx])
    
    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡å¼•ç”¨
    figure_pattern = r'<figure[^>]*id="([^"]*)"[^>]*>.*?<embed[^>]*src="([^"]*)"[^>]*/>.*?<figcaption>(.*?)</figcaption>.*?</figure>'
    matches = re.findall(figure_pattern, main_content, re.DOTALL)
    
    for match in matches:
        fig_id, src, caption = match
        # æ¸…ç†captionä¸­çš„HTMLæ ‡ç­¾å’Œå¤šä½™ç©ºç™½
        caption = re.sub(r'<[^>]+>', '', caption).strip()
        caption = re.sub(r'\s+', ' ', caption)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯qualitativeç›¸å…³çš„å›¾ç‰‡ï¼Œå¹¶æ’é™¤é™„å½•ä¸­çš„å›¾ç‰‡
        if ('qualitative' in fig_id.lower() or 'qualitative' in caption.lower()) and 'appendix_figures' not in src:
            figures.append({
                'id': fig_id,
                'src': src,
                'caption': caption,
                'type': 'qualitative'
            })
    
    return figures


class FAISSRetriever:
    """åŸºäºFAISSçš„å¯†é›†å‘é‡æ£€ç´¢å™¨"""
    
    def __init__(self):
        self.vector_store = None
        self.documents = []
        self.embeddings = None
        
    def _get_embeddings(self):
        """è·å–embeddingæ¨¡å‹"""
        if self.embeddings is not None:
            return self.embeddings
            
        # æ£€æŸ¥Azure OpenAIé…ç½®
        if os.getenv("AZURE_OPENAI_ENDPOINT") and os.getenv("AZURE_OPENAI_API_KEY"):
            endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-06-01")
            
            self.embeddings = AzureOpenAIEmbeddings(
                azure_endpoint=endpoint,
                openai_api_version=api_version,
                openai_api_key=api_key,
                model="text-embedding-3-large"
            )
            print("   ğŸ”— ä½¿ç”¨ Azure OpenAI Embeddings")
        else:
            # ä½¿ç”¨OpenAI API
            self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
            print("   ğŸ”— ä½¿ç”¨ OpenAI Embeddings")
        
        return self.embeddings
    
    def fit(self, documents: List[str]):
        """æ„å»ºFAISSç´¢å¼•"""
        if not HAS_LANGCHAIN:
            raise ImportError("éœ€è¦å®‰è£…langchainæ¥ä½¿ç”¨FAISSæ£€ç´¢")
        
        self.documents = documents
        
        # åˆ›å»ºDocumentå¯¹è±¡
        docs = [Document(page_content=doc) for doc in documents]
        
        # æ–‡æœ¬åˆ†å‰²å™¨
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_documents(docs)
        
        # è·å–embeddingså¹¶æ„å»ºFAISSç´¢å¼•
        embeddings = self._get_embeddings()
        self.vector_store = FAISS.from_documents(chunks, embeddings)
        
        print(f"   ğŸ“Š FAISSç´¢å¼•æ„å»ºå®Œæˆ: {len(chunks)} ä¸ªchunks")
    
    def search(self, query: str, top_k: int = 3) -> List[tuple]:
        """æœç´¢æœ€ç›¸å…³çš„æ–‡æ¡£"""
        if self.vector_store is None:
            return []
        
        # ä½¿ç”¨FAISSæ£€ç´¢
        retriever = self.vector_store.as_retriever(search_kwargs={"k": top_k})
        try:
            # ä½¿ç”¨æ–°çš„invokeæ–¹æ³•
            docs = retriever.invoke(query)
        except AttributeError:
            # å›é€€åˆ°æ—§æ–¹æ³•
            docs = retriever.get_relevant_documents(query)
        
        # è¿”å›ç»“æœ
        results = []
        for i, doc in enumerate(docs):
            # æ‰¾åˆ°åŸå§‹æ–‡æ¡£çš„ç´¢å¼•
            original_idx = self._find_original_doc_index(doc.page_content)
            if original_idx != -1:
                results.append((original_idx, 1.0 - i * 0.1))  # ç®€å•çš„åˆ†æ•°è®¡ç®—
        
        return results
    
    def _find_original_doc_index(self, content: str) -> int:
        """æ‰¾åˆ°chunkå¯¹åº”çš„åŸå§‹æ–‡æ¡£ç´¢å¼•"""
        for i, doc in enumerate(self.documents):
            if content[:100] in doc:  # ä½¿ç”¨å‰100ä¸ªå­—ç¬¦åŒ¹é…
                return i
        return -1



def get_semantic_context_for_figure(markdown_content: str, caption: str) -> str:
    """ä½¿ç”¨FAISSæ£€ç´¢æ‰¾åˆ°ä¸å›¾ç‰‡ç›¸å…³çš„ä¸Šä¸‹æ–‡å†…å®¹"""
    if not HAS_LANGCHAIN:
        print("   âŒ langchain æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨FAISSæ£€ç´¢")
        return ""
    
    lines = markdown_content.split('\n')
    
    # æ‰¾åˆ°é™„å½•å¼€å§‹çš„ä½ç½®ï¼ˆæ’é™¤é™„å½•å†…å®¹ï¼‰
    appendix_start_idx = len(lines)  # é»˜è®¤æ²¡æœ‰é™„å½•
    for i, line in enumerate(lines):
        line_lower = line.lower().strip()
        # æ£€æŸ¥æ˜¯å¦æ˜¯é™„å½•æ ‡é¢˜
        if (line_lower.startswith('# appendix') or 
            line_lower.startswith('## appendix') or
            line_lower.startswith('### appendix') or
            line_lower.startswith('# supplementary') or
            line_lower.startswith('## supplementary') or
            line_lower.startswith('### supplementary') or
            'appendix' in line_lower and line_lower.startswith('#')):
            appendix_start_idx = i
            break
    
    # å°†æ–‡æ¡£åˆ†å‰²æˆæ®µè½ï¼ˆåªè€ƒè™‘æ­£æ–‡éƒ¨åˆ†ï¼Œæ’é™¤é™„å½•ï¼‰
    paragraphs = []
    current_paragraph = []
    
    for i, line in enumerate(lines[:appendix_start_idx]):  # åªå¤„ç†æ­£æ–‡éƒ¨åˆ†
        line = line.strip()
        if not line:
            if current_paragraph:
                paragraphs.append(' '.join(current_paragraph))
                current_paragraph = []
        elif not line.startswith('<figure') and not line.startswith('<embed') and not line.startswith('<figcaption'):
            current_paragraph.append(line)
    
    # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
    if current_paragraph:
        paragraphs.append(' '.join(current_paragraph))
    
    # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ®µè½
    paragraphs = [text for text in paragraphs if len(text) > 50]
    
    if not paragraphs:
        return ""
    
    # ä½¿ç”¨FAISSæ£€ç´¢
    try:
        print("   ğŸ” ä½¿ç”¨FAISSå¯†é›†æ£€ç´¢...")
        retriever = FAISSRetriever()
        retriever.fit(paragraphs)
        
        # æ„å»ºæŸ¥è¯¢ï¼šä½¿ç”¨captionä½œä¸ºæŸ¥è¯¢ï¼Œå¦‚æœæ˜¯æ¯”è¾ƒå›¾åˆ™æ‰©å±•æŸ¥è¯¢è¯
        query = caption
        if "comparison" in caption.lower() or "compare" in caption.lower():
            # å¯¹äºæ¯”è¾ƒå›¾ï¼Œæ·»åŠ ä¸€äº›å¯èƒ½çš„æ–¹æ³•ç›¸å…³è¯æ±‡æ¥æ‰©å¤§æ£€ç´¢èŒƒå›´
            query += " methods comparison state-of-the-art baseline"
        print(f"   ğŸ” FAISSæŸ¥è¯¢: {query[:100]}...")
        
        # æœç´¢æœ€ç›¸å…³çš„æ®µè½ï¼ˆå¢åŠ æ•°é‡ä»¥è·å–æ›´å¤šä¸Šä¸‹æ–‡ï¼‰
        results = retriever.search(query, top_k=5)
        
        # æå–ç›¸å…³æ®µè½
        relevant_contexts = []
        for doc_idx, score in results:
            if score > 0:  # åªä¿ç•™æœ‰åˆ†æ•°çš„ç»“æœ
                text = paragraphs[doc_idx]
                relevant_contexts.append(text)
                print(f"   ğŸ“„ æ‰¾åˆ°ç›¸å…³æ®µè½ (åˆ†æ•°: {score:.3f}): {text[:100]}...")
        
        return '\n\n'.join(relevant_contexts)
        
    except Exception as e:
        print(f"   âŒ FAISSæ£€ç´¢å¤±è´¥: {e}")
        return ""



def reason_about_qualitative_figure(caption: str, context: str, paper_content: str) -> Dict:
    """ä½¿ç”¨GPT-o3æ¨ç†qualitativeå›¾ç‰‡åº”è¯¥æ˜¾ç¤ºä»€ä¹ˆ"""
    
    # Azure OpenAI é…ç½®
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "https://linjl-ma65uv6u-eastus2.cognitiveservices.azure.com/")
    api_key = os.getenv("AZURE_OPENAI_API_KEY", "")
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "o3-DR")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2025-01-01-preview")
    
    if not api_key:
        return {"error": "Azure OpenAI API key not found"}
    
    # æ„å»ºè¯·æ±‚URL
    url = f"{endpoint}openai/deployments/{deployment}/chat/completions?api-version={api_version}"
    headers = {"Content-Type": "application/json", "api-key": api_key}
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""You are analyzing a research paper figure. Based on the caption and context, reason about what this qualitative figure should show.

**Figure Caption:**
{caption}

**Context around the figure:**
{context}

**Additional paper content:**
{paper_content[:3000]}...

**IMPORTANT INSTRUCTIONS:**
1. **STRICTLY follow the caption**: The caption is the primary source of truth for what this figure shows
2. **For comparison detection**: Only mark as comparison if the caption explicitly mentions "comparison", "compare", "versus", "vs", or similar comparison words
3. **Do NOT infer comparison from context**: Even if the context contains comparison tables or mentions multiple methods, only consider it a comparison figure if the caption explicitly states it
4. **Context is supplementary**: Use context only to understand the research domain and provide additional details, but do not let it override the caption's primary meaning

**Your task:**
Analyze what this figure should contain based PRIMARILY on the caption, with context as supplementary information. Only identify this as a comparison figure if the caption explicitly mentions comparison.

Please provide your analysis in the following JSON format:
{{
  "figure_analysis": {{
    "purpose": "What is the main purpose of this figure?",
    "research_domain": "What field/domain is this research in?",
    "is_comparison": true/false,
    "methods_compared": ["List of specific method names if this is a comparison figure"],
    "evaluation_aspects": ["List of aspects being evaluated"],
    "expected_visual_elements": ["List of visual elements that should be present"],
    "scenarios_shown": ["List of scenarios or examples shown"],
    "key_differences": "Description of expected differences if this is a comparison figure"
  }},
  "detailed_reasoning": "Detailed explanation of what the figure should show",
  "visual_description": "Detailed description of what the figure should look like visually"
}}"""

    payload = {
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "max_tokens": 2000,
        "temperature": 0.1
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        
        data = response.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "{}")
        
        # å°è¯•è§£æJSON
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            result = json.loads(content)
            return result
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æå–markdownä»£ç å—ä¸­çš„JSON
            try:
                # æŸ¥æ‰¾```jsonå’Œ```ä¹‹é—´çš„å†…å®¹
                json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
                if json_match:
                    json_content = json_match.group(1)
                    result = json.loads(json_content)
                    return result
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œè¿”å›åŸå§‹å†…å®¹
                    return {
                        "raw_response": content,
                        "error": "Failed to parse JSON response"
                    }
            except json.JSONDecodeError:
                # å¦‚æœè¿˜æ˜¯è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
                return {
                    "raw_response": content,
                    "error": "Failed to parse JSON response"
                }
            
    except Exception as e:
        return {"error": f"API request failed: {str(e)}"}

def test_paper(paper_dir: Path, paper_name: str):
    """æµ‹è¯•å•ä¸ªè®ºæ–‡"""
    print(f"\n{'='*60}")
    print(f"ğŸ“š æµ‹è¯•è®ºæ–‡: {paper_name}")
    print(f"{'='*60}")
    
    # æŸ¥æ‰¾markdownæ–‡ä»¶
    markdown_path = paper_dir / "output_pandoc.md"
    if not markdown_path.exists():
        print(f"âŒ æœªæ‰¾åˆ°markdownæ–‡ä»¶: {markdown_path}")
        return None
    
    print(f"ğŸ“„ è¯»å–markdownæ–‡ä»¶: {markdown_path}")
    try:
        with open(markdown_path, 'r', encoding='utf-8') as f:
            markdown_content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None
    
    # æå–qualitativeå›¾ç‰‡
    print("\nğŸ” æå–qualitativeå›¾ç‰‡...")
    figures = extract_qualitative_figures(markdown_content)
    
    if not figures:
        print("âŒ æœªæ‰¾åˆ°qualitativeå›¾ç‰‡")
        return {
            "paper_name": paper_name,
            "paper_dir": str(paper_dir),
            "figures_found": 0,
            "figures": [],
            "results": []
        }
    
    print(f"âœ… æ‰¾åˆ° {len(figures)} ä¸ªqualitativeå›¾ç‰‡")
    
    # åˆ†ææ¯ä¸ªå›¾ç‰‡
    results = []
    for i, figure in enumerate(figures, 1):
        print(f"\nğŸ“Š åˆ†æå›¾ç‰‡ {i}: {figure['id']}")
        print(f"   Caption: {figure['caption'][:100]}...")
        
        # ä½¿ç”¨æ£€ç´¢æå–ç›¸å…³ä¸Šä¸‹æ–‡
        full_context = get_semantic_context_for_figure(markdown_content, figure['caption'])
        
        # è¾“å‡ºæå–åˆ°çš„ä¸Šä¸‹æ–‡ç”¨äºè°ƒè¯•
        print(f"   ğŸ“„ æå–åˆ°çš„ä¸Šä¸‹æ–‡:")
        print(f"   {'='*50}")
        print(f"   {full_context[:300]}...")
        print(f"   {'='*50}")
        
        # æ¨ç†å›¾ç‰‡å†…å®¹
        reasoning_result = reason_about_qualitative_figure(
            figure['caption'], 
            full_context, 
            markdown_content
        )
        
        result = {
            "figure_info": figure,
            "context": full_context,
            "reasoning": reasoning_result
        }
        results.append(result)
        
        # æ˜¾ç¤ºç»“æœ
        if "error" not in reasoning_result:
            print("âœ… æ¨ç†å®Œæˆ")
            if "figure_analysis" in reasoning_result:
                analysis = reasoning_result["figure_analysis"]
                print(f"   ğŸ“‹ ç›®çš„: {analysis.get('purpose', 'N/A')}")
                print(f"   ğŸ”¬ æ¯”è¾ƒæ–¹æ³•: {', '.join(analysis.get('methods_compared', []))}")
        else:
            print(f"âŒ æ¨ç†å¤±è´¥: {reasoning_result['error']}")
    
    return {
        "paper_name": paper_name,
        "paper_dir": str(paper_dir),
        "figures_found": len(figures),
        "figures": figures,
        "results": results
    }

def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æ‰€æœ‰è®ºæ–‡"""
    print("ğŸ” æµ‹è¯•æ‰€æœ‰è®ºæ–‡çš„é€šç”¨æ€§")
    print("=" * 60)
    
    # è®ºæ–‡ç›®å½•
    papers_dir = Path(__file__).parent.parent.parent / "workspace" / "papers_latex"
    
    # è·å–æ‰€æœ‰è®ºæ–‡ç›®å½•
    paper_dirs = [d for d in papers_dir.iterdir() if d.is_dir() and d.name.startswith('arXiv-')]
    
    if not paper_dirs:
        print("âŒ æœªæ‰¾åˆ°è®ºæ–‡ç›®å½•")
        return
    
    print(f"ğŸ“š æ‰¾åˆ° {len(paper_dirs)} ä¸ªè®ºæ–‡ç›®å½•")
    
    # æµ‹è¯•æ¯ä¸ªè®ºæ–‡
    all_results = []
    for paper_dir in paper_dirs:
        paper_name = paper_dir.name
        result = test_paper(paper_dir, paper_name)
        if result:
            all_results.append(result)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœ
    output_path = Path(__file__).parent / "all_papers_test_results.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
    print(f"{'='*60}")
    
    total_papers = len(all_results)
    total_figures = sum(r["figures_found"] for r in all_results)
    successful_analyses = 0
    
    for result in all_results:
        paper_name = result["paper_name"]
        figures_found = result["figures_found"]
        successful = sum(1 for r in result["results"] if "error" not in r["reasoning"])
        
        print(f"ğŸ“š {paper_name}:")
        print(f"   ğŸ“Š æ‰¾åˆ° {figures_found} ä¸ªqualitativeå›¾ç‰‡")
        print(f"   âœ… æˆåŠŸåˆ†æ {successful}/{figures_found} ä¸ªå›¾ç‰‡")
        
        successful_analyses += successful
    
    print(f"\nğŸ¯ æ€»ä½“ç»Ÿè®¡:")
    print(f"   ğŸ“š æµ‹è¯•è®ºæ–‡æ•°: {total_papers}")
    print(f"   ğŸ“Š æ€»å›¾ç‰‡æ•°: {total_figures}")
    print(f"   âœ… æˆåŠŸåˆ†æ: {successful_analyses}/{total_figures}")
    print(f"   ğŸ“ˆ æˆåŠŸç‡: {successful_analyses/total_figures*100:.1f}%" if total_figures > 0 else "   ğŸ“ˆ æˆåŠŸç‡: N/A")
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    main()
